{"chapters":[{"name":"Cíl prÆce","content":[{"type":"text/normal","text":"Cílem prÆce je navrhnout a implementovat algoritmy, potřebnØ pro analýzu videa, na detekci a sledovÆní objekt•. SledovanØ objekty by měly být jak lidØ, tak ostatní objekty reÆlnØho světa, a systØm by měl dokÆzat jejich rozeznÆní. SystØm ře†ící tento problØm by měl slou”it jako analyzÆtor videa, který po- skytne informace o pohybu lidí ve sledovanØ oblasti. Tento výstup bude ve formě teplotní mapy (více o teplotních mapÆch v kapitole 2.1.6)."},{"type":"text/large","text":"1.1 Popis ře†enØho problØmu"},{"type":"text/normal","text":"Analýza pohybu z videozÆznamu m•”e být jednoduchý problØm, ale takØ velice slo”itý. V†e zÆle”í na zp•sobu analýzy pohybu a vlastností, kterØ se mají za- znamenÆvat. Pokud postačuje jednoduchØ rozhodnutí, zda je na videu nějaký pohyb či nikoli, bude aplikace ře†ící tento problØm velice jednoduchÆ. Jeden z nejslo”itěj†ích problØm• v analýze obraz• a videa, je rozhodně strojovÆ klasiﬁkace a rozeznÆvÆní objekt•. Tento problØm je například pro člověka triviÆlní. Na†e neuronovØ sítě v mozku jsou propojeny a naučeny na- tolik dobře, ”e rozeznÆní obličej• nÆm m•”e trvat nejh•ře vteřiny a navíc na†e mo”nosti rozpoznÆní jsou, i oproti dne†ním nejlep†ím algoritm•m, mnohonÆ- sobně œspě†něj†í. Počítač je odkÆzÆn na kvalitu implementovaných algoritm•. Ty se vyvíjejí od raných počÆtk• počítačovØho vidění a za tu dobu bylo pu- blikovÆno mnoho prací a postup•. Moderní metody jsou bezpochyb, oproti dřívěj†ím, výrazně lep†í, ale některØ star†í techniky se dnes stÆle hojně pou”í- vají, proto”e nabízejí dostatečný poměr mezi kvalitou detekce, jednoduchostí a výkonem. ProblØm klasiﬁkace je nejenom jeden z nejnÆročněj†ích disciplín v počítačovØm vidění, ale takØ jeden z nejvíce zkoumaných, proto”e nabízí velikØ mo”nosti zlep†ení. Po vyře†ení problØmu detekce objekt• a jejich separace, je na řadě samotnØ sledovÆní detekovaných objekt•. I tento problØm nabízí ohromnou †kÆlu mo”- ných ře†ení. JednoduchØ postupy na ka”dØm snímku videa naleznou objekty popředí, kterØ jsou porovnÆvÆny s ji” detekovanými objekty dříve. TakovØ po-"},{"type":"text/normal","text":"rovnÆvÆní se m•”e provÆdět podle r•zných vlastností objektu, jako například barva nebo tvar. A” po komplexněj†í postupy ře†ení, kterØ staví na pravdě- podobnØm pohybu objektu a nÆslednØm zpřesnění polohy. Takový algoritmus u ka”dØho sledovanØho objektu uchovÆvÆ informace, podle kterých vypočítÆvÆ jeho pravděpodobnou novou polohu. Mezi takovØ informace se řadí rychlost, směr pohybu nebo orientace objektu. K výslednØmu zpřesnění polohy objektu se vyu”ijí dal†í jeho vlastnosti, stejně jako u přede†lØ metody barva nebo tvar, ale mohou mít přesněj†í reprezentaci. Díky odhadu novØ polohy objektu se ne- musí prohledÆvat celý nový snímek a stačí se omezit jen na vytyčenou oblast. To nÆm m•”e u†etřit i výpočetní výkon, kdy prohledÆvÆní jen čÆsti snímku je časově mØně nÆročnØ, ne” prohledÆvÆní celØho snímku. Díky získaným infor- macím o objektu se m•”e postupně přesnost sledovÆní zvy†ovat. Mezi překÆ”ky při sledovÆní objekt• patří čÆstečnØ nebo œplně překrytí ob- jekt•, nÆhlÆ změna pohybu objektu, změny vzhledu pozadí nebo sledovanØho objektu. Tyto situace jsou vět†inou mÆlo předvídatelnØ a robustní algoritmy si s nimi musí poradit. Moderní zp•soby ře†ení klasiﬁkace lidí staví na přednaučení modelu, který je pak porovnÆvÆn s nalezenými objekty. Tato metoda se zdÆ být efektivní a nabízí vysokou œspě†nost, av†ak je implementačně slo”itěj†í a její œspě†nost se odvíjí od kvality trØnovacího vzorku dat."},{"type":"text/large","text":"1.2 Vymezení cíl• a po”adavk•"},{"type":"text/normal","text":"Hlavními po”adavky na funkčnost jsou:"},{"type":"text/normal","text":"1. Výstup ve formě teplotních map, kterØ zobrazují nejfrekventovaněj†í místa pohybu objekt•."},{"type":"text/normal","text":"2. SystØm který dokÆ”e videozÆznam zpracovÆvat v reÆlnØm čase."},{"type":"text/normal","text":"3. SledovÆní objekt• po dobu jejich výskytu na zÆznamu."},{"type":"text/normal","text":"4. Klasiﬁkace lidí a ostatních objekt•, kterØ se objeví ve sledovanØm pro- storu."},{"type":"text/normal","text":"SystØm by měl tedy pracovat v reÆlnØm čase pro libovolný vstupní video- zÆznam, a· ulo”enØ video nebo přímý přenos z kamery. ZpracovÆvÆní informací bude provÆděno v”dy jen pro jeden video vstup. Předností systØmu by měla být jeho snadnØ pou”ívÆní. Předpokladem je, ”e systØm bude mo”nØ pou”ít bez jakýchkoliv dal†ích zÆsah• u”ivatele. Tedy v ideÆlním případě si u”ivatel systØm stÆhne, nastaví nutnØ informace a bez dal†ích zÆsah• systØm spustí. PředpoklÆdÆ se vyu”ívÆní systØmu v dlouho- dobØm časovØm rozmezí, je tedy d•le”itØ, aby takovýto chod zvlÆdal a po- stupem času nezvět†ovat svojí zÆtě” na výpočetní výkon, ani jinØ systØmovØ prostředky."},{"type":"text/normal","text":"Charakter systØmu umo”‹uje vyu”ít mØně dokonalý detektor lidí, který se bude projevovat men†í œspě†ností sprÆvně klasiﬁkovat osoby, na œkor men†í nÆročnosti na výpočetní výkon."},{"type":"text/large","text":"1.3 Struktura prÆce"},{"type":"text/normal","text":"Struktura prÆce je rozdělena do kapitol. V kapitole 2 bude shrnut obor po- čítačovØho vidění. ZÆkladní poznatky a mo”nÆ ře†ení problematiky sledovÆní, segmentace a klasiﬁkace objekt•, zde bude takØ popsÆno. V nÆsledující ka- pitole 3 budou představeny ji” existující systØmy, ře†ící podobný problØm, a představení zvolenØho implementačního prostředí. Poslední kapitola 4 bude obsahovat popsÆní výslednØ implementace systØmu, její nedostatky a mo”nÆ budoucí vylep†ení. V†e bude nakonec shrnuto v zÆvěru."},{"type":"text/large","text":"Kapitola"},{"type":"text/small","text":"2"}]},{"name":"PočítačovØ vidění","content":[{"type":"text/normal","text":"PočítačovØ vidění je snaha počítač naučit vidět stejně jako lidØ."},{"type":"text/normal","text":"Jak ji” bylo napsÆno, počítačovØ vidění je obor velice rychle rostoucí a v posledním desetiletí si získal takØ velikou oblibu. Rozvoj tohoto oboru se m•”e vÆzat na zvy†ovÆní výpočetního výkonu počítač• a takØ roz†ířením volně dostupných, lØpe či h•ře fungujících, otevřených knihoven, implementujících zÆkladní algoritmy vyu”ívanØ v počítačovØm vidění. Díky takovým knihovnÆm je dnes velice snadnØ začít vyvíjet systØmem, který je postaven na počítačovØm vidění a zpracovÆvÆní graﬁckØho obsahu."},{"type":"text/normal","text":"Mezi oblasti počítačovØho vidění patří tedy zejmØna sledovÆní a rozpoznÆ- vÆní objekt•. Ale to není jedinØ vyu”ití. M•”e se jedna o zpracovÆní obraz•, kde slou”í převÆ”ně k odstranění †umu z obraz•, jiných ne”Ædoucích jev• nebo naopak modiﬁkace vstupního obrazu, jako změna rozměr• či jinØ morfologickØ operace obrazu. V medicíně se m•”e počítačovØ vidění vyu”ít pro vytvÆření model• orgÆn•, například mozku, díky ním” jdou lØpe provÆdět diagnózy. DÆle to jsou r•znØ rekonstrukce scØny, například tvorba 3D modelu ze sØrie snímk• nebo panoramatickØ fotograﬁe."},{"type":"text/normal","text":"ObrÆzek 2.1: Zleva doprava: originÆlní obraz, obraz po přidÆní †umu, odstra- nění †umu pomocí GaussovskØ distribuce"},{"type":"text/normal","text":"ObrÆzek 2.2: Příklad jak je obraz sklÆdÆn z jednotlivých pixel•. [3]"},{"type":"text/large","text":"2.1 ZpracovÆní obrazu"},{"type":"text/plus","text":"2.1.1 Pixel"},{"type":"text/normal","text":"Pixel je samostatný bod reprezentující určitou barvu. Pokud budeme repre- zentovat pixel ve stupních †edi, postačí nÆm na jeho ulo”ení pouhý jeden byte (256 odstín• †edi). Při reprezentaci v barevnØm modelu se vět†inou hod- nota pixelu sklÆdÆ z více slo”ek. Například v barevnØm modelu RGB, je pixel reprezentovÆn třemi barvami (červenÆ, zelenÆ a modrÆ) a jejich kombinací vznikne výslednÆ barva, tak jak ji vnímÆme lidským okem. V počítačovØm vidění se vět†inou pracuje s intenzitou pixelu, co” je hodnota kombinující v†echny slo”ky, ze kterých se pixel sklÆdÆ."},{"type":"text/plus","text":"2.1.2 Obraz"},{"type":"text/normal","text":"Obraz je slo”en z pixel•, kterØ jsou uspořÆdÆny vedle sebe. Na obrazu 2.2 jsou viditelnØ jednotlivØ pixely, kterØ jako celek tvoří obraz. Pro œčely počítačovØho vidění musíme na†e vnímÆní 3D světa namapovat do počítačovØ reprezentace. Nejlep†ím mo”ným zp•sobem je reprezentovat obraz jako 2D matici a jednot- livØ prvky matice představují jeden pixel. Při takovØm zobrazení z na†eho 3D vnímÆní okolí do 2D reprezentace, bohu”el ztrÆcíme některØ cennØ informace o scØně, například hloubku."},{"type":"text/normal","text":"Obraz mÆ vlastnosti jako barevnØ schØma, ve kterØm jsou reprezentovÆny jednotlivØ pixely, †ířku a vý†ku. Šířka a vý†ka je označovÆna jako rozli†ení obrazu a zapisovÆna ve formÆtu †ířka × vý†ka. Tyto hodnoty udÆvají počet pixel• v danØm směru. Například obraz s †ířkou 1024 a vý†kou 720 (značeno 1024 × 720), obsahuje 1024 ∗ 720 = 737280 samostatných pixel•."},{"type":"text/normal","text":"JednotlivØ pixely obrazu jsou indexovÆny pomocí x a y souřadnic od po- čÆtečního (0,0) bodu."},{"type":"text/plus","text":"2.1.3 Video"},{"type":"text/normal","text":"Video je tvořeno sekvencí obraz•. Je to tedy jakýsi „kontejner“ pro obrazy, který je zobrazuje v danØm pořadí a počtu snímk• za sekundu. JednotlivØ obrazy ve videu jsou v tØto prÆci označovÆny slovem snímek. Počet snímk• za sekundu (fps) udÆvÆ kolik snímk• se mÆ z videa zobrazit za dobu jednØ vteřiny. Video o dØlce 5 vteřin a 25 fps, obsahuje sekvenci 125 snímk•. V†echny snímky z jednoho videa mají vět†inou stejnØ rozli†ení."},{"type":"text/normal","text":"Aby člověk vnímal video jako plynulØ, musí mít nejmØně 24 snímk• za sekundu. Pokud tedy chceme aby systØm, který mÆ zobrazovat výstup, byl vnímÆn jako plynulý (tedy v reÆlnØm čase), musíme zpracovÆvat jeden snímek z video sekvence nejh•ře za dobu 41ms."},{"type":"text/plus","text":"2.1.4 Feature"},{"type":"text/normal","text":"Pojem feature, v počítačovØm vidění, zastupuje jakýsi obecný termín popisu- jící informaci o vlastnosti a přesnÆ deﬁnice v”dy zÆvisí na konkrØtním pro- blØmu. Obecně se jednÆ o struktury obsa”enØ v obrazu (m•”e to být bod, hrana nebo celkový objekt). Je to tedy jakÆsi vlastnost obrazu, ale v někte- rØm kontextu by pojem vlastnost mohl být matoucí. U klasiﬁkace, feature m•”e zastupovat například barvu, tvar nebo rozlo”ení a počet klíčových bod• 2.1.4."},{"type":"text/normal","text":"V†echny techniky počítačovØho vidění jsou na features velice zÆvislØ, pro- to”e ovliv‹ují jejich celkovou œspě†nost. Proto kvalita features, a takØ kvalita jejich detekce, jsou udÆvajícím faktorem œspě†nosti výsledku. Je potřeba, aby vybranØ features bylo mo”nØ nalØzt v dal†ích obrazech nebo snímcích, proto se vybírají jen takovØ features, kterØ mají velkou informativní hodnotu."},{"type":"text/normal","text":"Hrana a Obrys"},{"type":"text/normal","text":"Hrana je čÆst obrazu kde se mění jedna barva na druhou. Přesněji hranice mezi rozdílnými intenzitami barev. Takto funguje jednoduchý hranový detektor, projde celý obraz a ka”dý pixel ohodnotí číslem, kterØ odpovídÆ vzdÆlenosti jeho intenzity od intenzity pixelu sousedního. PotØ v†echny pixely, kterØ mají ohodnocení vět†í ne” určitÆ mez, jsou označeny jako součÆst hrany. Existující hranovØ detektory [4, 5]."},{"type":"text/normal","text":"SamotnÆ hrana nÆm o objektu ke kterØmu nÆle”í moc neřekne. Kdy” nalez- neme hrany v obrazu, tak je†tě nemusíme dostat segmentovaný objekt (pojem segmentace bude vysvětlen později 2.1.7), proto”e mohou být hrany více ob- jekt• vzÆjemně spojeny. M•”eme v†ak nalØzt celkový obrys objektu na zÆkladě nalezených hran jejich shlukovÆním, v binÆrního obrazu v†echny „bilØ“ plochy nebo jiných postup• [6]."},{"type":"text/normal","text":"ObrÆzek 2.3: Histogram znÆzor‹ující rozlo”ení barev v obrazu."},{"type":"text/normal","text":"Klíčový bod"},{"type":"text/normal","text":"Klíčový bod (angl. interest point) je jednou z mo”ných feature objektu a m•”e být označen i jako „roh“ (angl. corner). JednÆ se o bod v obrazu, který je unikÆtní ve svØm okolí nebo obsahuje víc informací ne” jinØ body. Jako klíčovØ body v obrazu, jsou často označovÆny reÆlnØ „rohy“, tedy body, kde se pro- tínÆ dva a více hran. Nebo světlØ body s tmavým okolím, stejně tak jakØkoli body kde se mění intenzita barev, proto klíčovØ body často le”í na hranÆch. Detektory klíčových bod• [7, 8, 9]."},{"type":"text/normal","text":"Naopak velice †patnými kandidÆty na klíčovØ body jsou jednolitØ povrchy obrazu, kterØ nejsou nijak odli†nØ od okolí. Jejich sledovÆní ani nalezení na dal†ích snímcích je velice obtí”nØ, proto”e se mohou zaměnit za jinØ, velice podobnØ plochy."},{"type":"text/plus","text":"2.1.5 Histogram"},{"type":"text/normal","text":"Jednou z nejvyu”ívaněj†ích věcí v počítačovØm vidění jsou histogramy. Histo- gramy jsou ale pou”ívanØ i v jiných oblastech a jsou velmi často vyu”ívÆny pro zobrazení nejr•zněj†ích naměřených informací. Pomocí nich se jednodu†e dají znÆzor‹ovat data o výskytu hodnot. JednÆ se o graf, nebo graﬁckØ znÆzor- nění, určitØ pozorovanØ vlastnosti. V počítačovØm vidění je příklad histogram obrazu, který poskytuje graﬁckØ znÆzornění celkovØho rozlo”ení v†ech barev."},{"type":"text/normal","text":"Řekněme, ”e mÆme obraz slo”en ze čtyř barev s rozli†ení 5 × 5. Ka”dý pixel je reprezentovÆn jednou z těchto barev. Pro ka”dou barvu zjistíme počet pixel• s danou barvou. DostÆvÆme čtyři skupiny s počtem pixel•, kterØ je rozlo”ení barev v obrazu a dÆ se graﬁcky znÆzornit. Histogram takto funguje a výsledek m•”e zobrazit jako graf 2.3."},{"type":"text/normal","text":"ObrÆzek 2.4: Teplotní mapa podle hustoty příjmení „DvořÆk“ v jednotlivých oblastech ČR s pou”itím dvou barevných schØmat. Převzato z [10]."},{"type":"text/plus","text":"2.1.6 Teplotní mapa"},{"type":"text/normal","text":"Teplotní mapy umo”‹ují graﬁcky znÆzor‹ovat 2D data, jak je ukÆzÆno na ob- razu 2.4. Barevně zobrazuje data podle jejich hodnoty, kdy nízkØ hodnoty dat mají jinou barvu ne” vysokØ hodnoty. To se provÆdí tak, ”e se nalezne největ†í a nejmen†í hodnota v datech. Toto rozmezí se rozdělí do několika men†ích interval•, kde ka”dØmu bude přiřazena barva. PotØ se postupně prochÆzejí hodnoty dat a podle toho, do kterØho intervalu hodnota patří je odpovídající pixel ohodnocen barvou intervalu."},{"type":"text/normal","text":"Barvy přiřazenØ interval•m dohromady tvoří barevnØ schØma teplotní mapy a pro r•znÆ data a r•znØmu œčelu, m•”e být v”dy pou”itØ schØma jinØ. Napří- klad barevnØ schØma, kde nízkØ hodnoty jsou reprezentovÆny světlou modrou barvou, potØ přechÆzejí do sytěj†ích barev, a” po sytě rudou barvou kterou jsou ohodnoceny nejvy††í hodnoty. TakovØto schØma je ideÆlní reprezentací pro člověka, proto”e poskytuje na první pohled patrnØ rozdíly mezi oblastmi s nízkými hodnotami a těmi s vysokými."},{"type":"text/normal","text":"Teplotní mapy se takØ vyu”ívají například pro vizualizaci oblastí webových strÆnek, kterou jsou nejvíce „čteny“ nÆv†těvníky, nebo na kterØ čÆsti je nejvíce klikÆno."},{"type":"text/plus","text":"2.1.7 Segmentace"},{"type":"text/normal","text":"Pro potřeby dal†ího zpracovÆní obraz• a videa potřebujeme od sebe rozli†it oblasti, kterØ mají stejnØ nebo podobnØ vlastnosti. Pomocí segmentace se takto dÆ předzpracovat obraz a dÆle na něm provÆdět dal†í potřebnØ kroky pro získÆní potřebnØho výstupu."},{"type":"text/normal","text":"Podle potřeb dal†ího zpracovÆní a výsledku se takØ musí vybrat postup, jak potřebnØ segmentace dosÆhnout. Pokud chceme z obrazu získat plochy konkrØtní barvy, vyu”ijeme segmentaci zalo”enou na barvě, kterÆ nÆm tyto oblasti zvýrazní. Nebo m•”eme segmentovat na zÆkladě hran obrazu, takto dostÆvÆme mo”nost od sebe oddělit objekty jednoduchým zp•sobem."},{"type":"text/normal","text":"ObrÆzek 2.5: Obraz v odstínech †edi byl pomocí prahovÆní upraven na binÆrní. OriginÆl převzat z [11]"},{"type":"text/normal","text":"PrahovÆní"},{"type":"text/normal","text":"PrahovÆní je operace, kterÆ modiﬁkuje vstupní obraz. Vstupní parametry al- goritmu je hodnota prahu T, kterÆ rozděluje hodnoty obrazu na dvě skupiny, minimÆlní hodnota min a maximÆlní hodnota max."},{"type":"text/normal","text":"V†echny hodnoty, kterØ jsou men†í ne” prÆh T, jsou převedeny na zadanou minimÆlní hodnotu min, a naopak, hodnoty vět†í ne” prÆh zase na maximÆlní hodnotu max. VyjÆdřeno rovnicí 2.1."},{"type":"text/small","text":"("},{"type":"text/normal","text":"min p(x,y) < T (2.1) p (x,y) ="},{"type":"text/small","text":"new"},{"type":"text/normal","text":"max p(x,y) > T"},{"type":"text/normal","text":"p(x,y) značí hodnotu danØho pixelu."},{"type":"text/normal","text":"Příkladem je prahovÆní obrazu ve stupních †edi. PrÆh byl zvolen na hod- notu 150 a výsledný obraz 2.5. Tomuto prahovÆní se říkÆ binÆrní, proto”e výsledný obraz se sklÆdÆ pouze ze dvou hodnot a to min a max."},{"type":"text/normal","text":"Vylep†ení metody přinesl ve svØ prÆci Otsu [12], kde bylo roz†ířeno praho- vÆní o nekonstantní prÆh T, který je upravovÆn na zÆkladě soused• pixelu, a tím se docílilo lep†í segmentace. Jeho přístup je dnes nejčastěji pou”ívÆn."},{"type":"text/normal","text":"K-mean shlukovÆní"},{"type":"text/normal","text":"Algoritmus slou”ící pro segmentaci obrazu do k shluk• [13]. k je vstupním parametrem před spu†těním algoritmu. Přiřazení pixelu do určitØho shluku se provÆdí na zÆkladě pr•měrnØ vzdÆlenosti ke středu shluk•. Středy shluk• mohou být vybrÆny algoritmem nÆhodně anebo vyu”ity nějakØ heuristickØ metody. K-mean shlukovÆní se vyu”ívÆ, mimo zpracovÆní obrazu, takØ v oblasti vytě”ovÆní dat, kde potřebujeme rozdělit vstupní skupinu dat do k oblastí."},{"type":"text/normal","text":"JednÆ se o techniku strojovØho učení a potØ se vyu”ívÆ při klasiﬁkaci nově napozorovaných bod•."},{"type":"text/normal","text":"V počítačovØm vidění jsou naopak středy shluk• vybírÆny například jako k nejvy††ích vrchol• v histogramu nebo takØ nÆhodně. Postupně jsou do shluk• přidÆvÆny pixely s podobnou barevnou intenzitou jakou mÆ jeho aktuÆlní střed. Středy mohou být takØ postupně aktualizovÆny, kdy pr•měrnÆ hodnota v†ech pixel• v danØm shluku bude novým středem. Takto m•”eme, za před- pokladu znÆmØho počtu objekt• s jednolitou barvou, jednodu†e segmentovat obraz nebo jej zjednodu†it pro dal†í zpracovÆní."},{"type":"text/normal","text":"Detekce hran"},{"type":"text/normal","text":"Předchozí dvě metody vyu”ívali pro segmentaci barevnØ schØma a po segmen- taci obraz obsahoval spojenØ oblasti s podobnou barevnou intenzitou. Detekce hran je alternativou pro tyto metody. Po aplikovÆní tØto segmentace na obraz, dostaneme výstupem seznam v†ech nalezených hran. Jak bylo dříve popsÆno v kapitole 2.1.4, hrana je hranice mezi dvěma oblastmi, a pro jejich nalezení se vyu”ívají dva hlavní postupy, porovnÆvÆní œsek• obrazu se †ablonou hran a nebo vypočítÆní gradientu. Více informací v [14, Kapitola 5: Edge detection]."},{"type":"text/large","text":"2.2 Detekce pohybu"},{"type":"text/normal","text":"Algoritmy, zaji†·ující detekci pohybu, pracují s aktuÆlním zachyceným sním- kem a libovolně velikou skupinou snímk• předchÆzejících. JednÆ se o formu segmentace objekt• popředí od pozadí scØny."},{"type":"text/plus","text":"2.2.1 OdčítÆní pozadí"},{"type":"text/normal","text":"Tato metoda je jednou ze zÆkladních technik analýzy sekvence snímk•. Snaha je ze sekvence snímk•, ze statickØ kamery, detekovat v†echny objekty popředí. Funguje na principu vytvoření referenčního modelu pozadí, který se potØ ode- čte od aktuÆlního snímku a tím se vytvoří obraz obsahující jen objekty po- předí. OdčítÆní pozadí pracuje s barevnou reprezentací pixel•. Na obrazu 2.2.1 je znÆzorněn diagram pr•běhu tØto metody."},{"type":"text/normal","text":"NÆsledující rovnice 2.2 udÆvÆ obecný vztah principu tØto metody. Výsledný obraz je potØ je†tě metodou prahovÆní zbaven †umu."},{"type":"text/normal","text":"|snímek − pozadí| > prÆh (2.2)"},{"type":"text/small","text":"t"},{"type":"text/normal","text":"Jak si lze v†imnou, výsledek je takØ citlivý na hodnotu zvolenØho prahu."},{"type":"text/normal","text":"Nejjednodu††í formou metody odečítÆní pozadí, je aktuÆlní snímek porov- nÆvat jen se snímkem předchÆzejícím 2.3. Metoda je to velice jednoduchÆ a výpočetně nenÆročnÆ, ale bohu”el neposkytuje velmi dobrý výsledek, proto”e m•”e „zvýraznit“ jen čÆst objektu popředí. Dal†í překÆ”kou u tØto metody"},{"type":"text/normal","text":"ObrÆzek 2.6: Diagram metody odčítÆní pozadí. Převzat z [15]"},{"type":"text/normal","text":"jsou malØ opakující se pohyby, kterØ jsou ale součÆstí pozadí. Například po- hyby strom• ve větru, kterØ by byly detekovanØ jako součÆst popředí. Mo”ným vylep†ením, který by ov†em ře†il jen čÆst problØm•, by mohlo být zvolit, jako referenční model pozadí, první snímek ze sekvence, nebo ten, který neobsahuje ”ÆdnØ objekty popředí a je tvořen jen pozadím. To je ale zÆvislØ na konkrØtním případě vyu”ití a vstupních datech."},{"type":"text/normal","text":"|snímek − snímek | > prÆh (2.3)"},{"type":"text/small","text":"t t−1"},{"type":"text/normal","text":"Dal†í překÆ”kou jsou takØ změny v osvětlení pozadí, kterØ by předchozí na- ivní metoda takØ označila jako objekt popředí. M•”e se jednat o nÆhlØ změny nebo postupnØ. U postupných změ‹ by mohla být situace vyře†ena pou”itím „ideÆlního“ prahu při zpracovÆní výslednØho snímku popředí. Proto”e v tako- vØm případě se hodnota pixelu m•”e od p•vodní li†it jen o malØ číslo, vhodně zvolený prÆh by v takovØm případě přinesl zlep†ení."},{"type":"text/normal","text":"ZnačnØ vylep†ení vychÆzí tedy z vytvÆření kvalitního modelu pozadí. Mezi existující techniky patří počítÆní pr•měru hodnot pixelu ze sekvence snímk• nebo pomocí reprezentace hodnoty pixelu pomocí GaussovskØ distribuce."},{"type":"text/normal","text":"PočítÆní pr•měru hodnot z předchozích n snímk• m•”e zlep†it výsledný model pozadí a tak zkvalitnit detekci změn. Naivním ře†ením je uchovÆvÆní předchozích n snímk• a z nich v”dy spočítat pr•měr pro ka”dý pixel obrazu. Tento přístup se dÆ zlep†it. Kdy” budeme hodnotu pozadí počítat rovnou při zpracovÆní vÆ”eným pr•měrem, nebudeme si muset uklÆdat zbytečně n − 1 snímk• navíc. PotØ je ka”dým novým snímkem model pozadí ovlivněn rovnicí 2.4."},{"type":"text/normal","text":"pozadí(x,y) = α ∗ snímek (x,y) + (1 − α) ∗ pozadí(x,y) (2.4)"},{"type":"text/small","text":"t t−1 t t−1 "},{"type":"text/normal","text":"α v tomto případě udÆvÆ míru učení, tedy jak moc ovlivní aktuÆlní hod- noty pixelu model pozadí. Pro malØ hodnoty α bude pozadí mØně ovlivněno a naopak pro velkØ hodnoty."},{"type":"text/normal","text":"Podobně při hledÆní hodnoty pixelu lze vyu”ít histogram•. Díky reprezen- taci hodnot pixelu pomocí histogramu, nalezneme tu hodnotu, kterÆ se nejvíce vyskytovala. Metoda histogram• byla roz†ířena pomocí [16], kdy místo kla- sickØho histogramu je hodnota pixelu modelovÆna Gaussovou funkcí, kterÆ slou”í jako pravděpodobnostní rozdělení hodnot pixelu. Tak získÆme pr•měr- nou hodnotu pixelu a odchylku od tØto hodnoty. Díky tomu dostÆvÆme rozmezí hodnot pixelu, kterØ se pova”ují za hodnoty pozadí. Z aktuÆlního snímku zís- kÆme hodnotu danØho pixelu a porovnÆme zda le”í v tomto rozmezí hodnot pozadí, jinak se jednÆ o popředí 2.5."},{"type":"text/small","text":"|I(x,y) −µ |"},{"type":"text/small","text":"t t  t t  "},{"type":"text/normal","text":"> P ∈ popředí"},{"type":"text/small","text":"σ"},{"type":"text/small","text":"t t  t t  "},{"type":"text/normal","text":"(2.5)"},{"type":"text/small","text":"|I(x,y) −µ |"},{"type":"text/small","text":"t t  t t  "},{"type":"text/normal","text":"< P ∈ pozadí"},{"type":"text/small","text":"σ"},{"type":"text/small","text":"t t  t t  "},{"type":"text/normal","text":"Kde I(x,y) označuje hodnotu pixelu na aktuÆlním snímku, µ je pr•měrnÆ"},{"type":"text/small","text":"t t−1 t t−1 "},{"type":"text/normal","text":"hodnota pixelu a σ značí mo”nou odchylku od pr•měru. P je poměr mezi"},{"type":"text/small","text":"t t−1 t t−1 "},{"type":"text/normal","text":"vzdÆleností I(x,y) od pr•měrnØ hodnoty a odchylkou distribuce. P zde plní funkci podobnou k u prahovÆní."},{"type":"text/normal","text":"Z tohoto přístupu vychÆzí roz†íření, kterØ nevyu”ívÆ jen jednu Gaussovu distribuci na reprezentaci hodnoty pixelu, nýbr” několik. P•vodně byla tato metoda představena pÆny Stauﬀer a Grimson [17]. K Gaussových distribucí, K je doporučeno malØ (podle [17] číslo v rozmezí 3 a” 5), kde ka”dÆ reprezen- tuje pravděpodobnost výskytu jednØ barvy a odpovídající pr•měrnou hodnotu a odchylku. Ka”dÆ Gaussova distribuce m•”e reprezentovat například barvu popředí nebo pozadí. Jde vlastně o K nejpravděpodobněj†ích barev, kterØ se mohou v danØm pixelu objevit. Rozhodnutí, zda je aktuÆlní hodnota pixelu pozadí nebo popředí, se provÆdí podobně jako u přede†lØho metody, ale je po- rovnÆvÆna se v†emi K Gaussovými distribucemi. Mohou nastat dva případy:"},{"type":"text/normal","text":"1. Shoda je nalezena v jednØ z K Gaussových distribucí. V takovØm pří- padě, pokud je to Gaussova distribuce pozadí, je pixel klasiﬁkovÆn jako součÆst pozadí, v opačnØm případě je pixel součÆstí popředí."},{"type":"text/normal","text":"2. Shoda v ”ÆdnØ Gaussovově distribuci nebyla nalezena. V takovØm pří- padě je pixel součÆstí popředí."},{"type":"text/normal","text":"Tato metoda získala velkou oblibu. Ale i kdy” přinÆ†í oproti předchozím značnØ vylep†ení segmentace, bylo publikovÆna mnoho dal†ích metod, kterØ ji dÆle vylep†ují [18, 19]. Ty se zaměřují jak na zlep†ení výpočetní nÆročnosti,"},{"type":"text/normal","text":"ObrÆzek 2.7: SrovnÆní metod odčítÆní pozadí. a) K Gaussova distribuce, b) vÆ”ený pr•měr, c) odčítÆní pouze předchozího snímku."},{"type":"text/normal","text":"tak i na zlep†ení segmentace popředí od pozadí. Existují i postupy tvorby pozadí, kterØ dokÆ”í rozeznat periodicky se opakující děje v pozadí a tak je chybně neoznačovat jako popředí, například mořskØ vlny. Více o metodÆch vyu”ívající Gaussovu distribuci se dÆ dočíst v člÆnku [20]."},{"type":"text/normal","text":"V†echny představenØ metody tvorby pozadí, zpracovÆvají obraz pouze s ohle- dem na jednotlivØ pixely nezÆvisle na sobě. To znamenÆ, ”e hodnota pixelu je počítÆna jenom jako hodnota odpovídajícího pixelu z předchozích snímk•. Existují ale i metody, kterØ vyu”ívají informací z okolí a jsou tak mØně nÆ- chylnØ na rapidní změny v celkovØm stavu obrazu [21]."},{"type":"text/large","text":"2.3 Klasiﬁkace objekt•"},{"type":"text/normal","text":"Po získÆní oblasti s mo”ným výskytem objektu, nalezenØho například pomocí metody odčítÆní pozadí, nÆsleduje potřeba rozeznat o jaký objekt se jednÆ. Nejd•le”itěj†ím faktorem u klasiﬁkace, je potřeba vybrÆní takových features, kterØ jsou pro objekt identiﬁkující. Pokud je potřeba rozli†ovat objekty zÆ- kladních neměnných tvar•, jako například čtverec, kruh nebo hvězda, postačí zjistit tvar objektu. Čtverec mÆ v”dy čtyři hrany a v†echny mají stejnou dØlku, proto tento œdaj postačuje pro jeho klasiﬁkaci. Pokud je ale potřeba rozeznat slo”itěj†í objekty, kterØ navíc nemají v”dy stejný tvar, musejí se vyu”ít metody,"},{"type":"text/normal","text":"ObrÆzek 2.8: RozeznÆní objektu je pro člověka snadný œkol. Pro počítač je to ale mnohem nÆročněj†í."},{"type":"text/normal","text":"kterØ dovolují rozli†it objekt s určitou pravděpodobností. Mo”ným postupem při klasiﬁkaci takovýchto objekt•, m•”e být vytvoření obecnØho modelu sku- piny, se kterým se budou detekovanØ objekty porovnÆvat."},{"type":"text/normal","text":"Jako lidØ nemÆme problØm s rozli†ením velkØho mno”ství objekt• v reÆl- nØm prostředí ani v obrazu, i kdy” je nějakým zp•sobem sní”ena jeho kvalita. Dokonce nejsme nÆchylní ani na rotace objekt• nebo změny velikosti. Tento problØm je v†ak stÆle velkou výzvou pro strojovØ vnímÆní počítače. Na pří- kladu 2.8 je zachycen obličej člověka."},{"type":"text/normal","text":"Musíme si uvědomit, ”e systØmy počítačovØho vidění v”dy dokÆ”í rozli†it pouze předdeﬁnovanØ objekty neboli ty, na kterØ byl klasiﬁkÆtor navrhnut a naučen. S přihlØdnutím na vstupní data, kterÆ vět†inou obsahují †um a mo- hou být rozdílnÆ, nejsou tyto klasiﬁkÆtory nikdy stoprocentní. V kontrastu od algoritm• na řazení dat, algoritmy počítačovØho vidění jsou œspě†nØ jen v ně- kterých případech a jejich autoři zveřej‹ují procento œspěchu na konkrØtních testovacích datech."},{"type":"text/plus","text":"2.3.1 JednoduchÆ klasiﬁkace"},{"type":"text/normal","text":"U klasiﬁkace objekt•, kterØ mají jednotnou barvu, se pou”ije barva jako fea- ture a podle ní se budou objekty klasiﬁkovat. K tomu je potřeba segmentace obrazu, kterÆ odstraní v†echny oblasti s jinou ne” hledanou barvou a výstu- pem budou jen oblasti výskytu objektu. Tento přístup se dÆ pou”ít u předem znÆmých objekt•, kterØ mají v”dy stejnou barvu. Například pokud je potřeba najít a klasiﬁkovat ovoce, bude nadeﬁnovÆno, ”e jahody mají červenou a ba- nÆny ”lutou barvu, postačí nejdříve vstupní obraz segmentovat pro tyto dvě barvy a najít zbylØ oblasti. Tyto oblasti budou označeny jako hledanØ ovoce. Navíc pokud se bude testovat tato metoda na sekvenci snímk• obsahující jen jahody a banÆny, m•”e se dostat na stoprocentní œspě†nost při klasiﬁkaci."},{"type":"text/normal","text":"ObrÆzek 2.9: GeometrickØ objekty jsou jedinečnØ tvarem, pětiœhelník mÆ pět hran a podobně u dal†ích."},{"type":"text/normal","text":"Tato klasiﬁkace samozřejmě funguje jen pro vstupní data, kterÆ obsahují pouze hledanØ objekty a mají stejnou podobu. Pokud jako vstup zvolíme sní- mek, na kterØm je červený míček, označí ho algoritmus chybně za jahodu. Podobně se m•”e postupovat i u klasiﬁkaci geometrických tvar•. Vhod- nou metodou segmentace obrazu se naleznou hledanØ oblasti, zjistí se obrys oblastí a na zÆkladě toho se objekty klasiﬁkují. Čtverec nebo hvězdu se tímto dají jednodu†e rozeznat, proto”e jejich tvar je přesně daný a pokud nalezenÆ oblast nebude odpovídat, bude jistØ, ”e to hledaný objekt není. Klasiﬁkace, podle tvar• objekt•, je znÆzorněna na obrazu 2.3.1. Například v [22] vypraco- vali metodu zalo”enou na podobnosti tvaru objektu, a dal†ích heuristik, pro nalezení a klasiﬁkaci objekt•. Výslednou metodu testovali na datech siluet, ručně psaných znak• a značek."},{"type":"text/plus","text":"2.3.2 Komplexněj†í klasiﬁkace"},{"type":"text/normal","text":"V tØto sekci bude představena skupina metod pro klasiﬁkaci zalo”enÆ na nau- čení modelu objektu, který se mÆ klasiﬁkovat. Tento postup se nazývÆ koordi- novanØ učení. Nejprve je potřeba zvolit podle jakØ feature se bude klasiﬁkÆtor učit rozli†ovat objekty. M•”e to být například barva objektu, jeho obrys nebo vzhled reprezentovaný pomocí histogram•. Metody učení takových model• zahrnují například neurÆlní sítě, rozhodovací stromy, adaptive boosting nebo support vector machines. Nevýhodou pro tyto metody je potřeba dostatečně velkØ kolekce vzor• pro ka”dý objekt, podle kterých se klasiﬁkÆtor naučí je rozli†ovat. Navíc tyto metody vy”adují, aby v†echny vzory byly označeny do jakØ skupiny objektu patří. Kvalita trØnovacích dat je takØ velice d•le”itÆ. Takto naučený klasiﬁkÆ- tor pracuje jen za určitých podmínek, kdy je hledaný objekt plně viditelný, nebo jen čÆstečně překrytý. Kvalitně naučený a robustně navrhnutý klasiﬁkÆ- tor je na tyto případy sice mØně nÆchylný, ale dostat se za ka”dých podmínek ke stoprocentní klasiﬁkaci, není ani v takovØm případě jednoduchý œkol."},{"type":"text/normal","text":"ObrÆzek 2.10: Nalezení nejlep†ího rozdělení dvou tříd pomocí SVM a krajní body."},{"type":"text/normal","text":"Support vector machine - SVM"},{"type":"text/normal","text":"SVM jako klasiﬁkÆtor rozděluje vstupní data na dvě třídy. První třída odpo- vídÆ hledanØmu objektu (pozitivní vzory) a druhÆ ostatním dat•m (negativní vzory). UkÆzka rozdělení 2.3.2. Proto tento klasiﬁkÆtor potřebuje pro naučení takØ negativní vzory. Principem je nalØzt takovou rovinu, kterÆ bude mít od okrajových bod• obou skupin největ†í vzdÆlenost, a takovým bod•m se říkÆ support vektory. JednÆ se o lineÆrní separaci dat, ale existují postupy, jak udělat z SVM nelineÆrní klasiﬁkÆtor."},{"type":"text/normal","text":"Naučený SVM klasiﬁkÆtor, pro ka”dý nový vstup, rozhodne do jakØ třídy nÆle”í a to tak, ”e místo aby porovnÆval vstup se v†emi daty, porovnÆvÆ jen se support vektory."},{"type":"text/normal","text":"Adaptive boosting (AdaBoost)"},{"type":"text/normal","text":"ZÆkladním principem AdaBoost algoritmu je zkombinovat mno”inu slabých"},{"type":"text/small","text":"1"},{"type":"text/normal","text":"klasiﬁkÆtor• . Příkladem m•”e být klasiﬁkace pohlaví člověk na zÆkladě vý†ky, kde osoby vy††í 180 cm budou klasiﬁkovÆny jako mu” a men†í jako ”ena. AdaBoost nÆsledně slabØ klasiﬁkÆtory ohodnotí vÆhou, kterou by při- spívaly do predikce, a na zÆkladě tØto vÆhy zkombinuje slabØ klasiﬁkÆtory do jednoho robustního klasiﬁkÆtoru."},{"type":"text/small","text":"1"},{"type":"text/small","text":"klasiﬁkÆtory kterØ mají malou œspě†nost predikce, ale lep†í ne” nÆhodnÆ klasiﬁkace"},{"type":"text/normal","text":"Bag-of-words (BOW)"},{"type":"text/normal","text":"Tento klasiﬁkÆtor pracuje s features objektu jako se „slovy“. Ka”dý trØnovací vzor reprezentuje pomocí vizuÆlních vlastností objektu, tedy vizuÆlních slov. NalezenÆ podobnÆ slova vzor• jsou shlukovÆna, aby vytvořila referenční vzorek pro detekci. NÆsledně je ka”dÆ třída reprezentovÆna podle výskytu slov, po- mocí histogramu, kde jsou u jednotlivých tříd spočteny výskyty jednotlivých slov a rozhodnutí, zda testovaný objekt nÆle”í do třídy, je zalo”eno na porov- nÆní histogram•. Tedy oba objekty musí obsahovat stejnÆ slova a o stejnØm počtu."},{"type":"text/normal","text":"BOW vyu”ívÆ dal†í algoritmy pro separaci dat a jejich klasiﬁkaci. Napří- klad metodu nejbli”†ích soused• nebo SVM."},{"type":"text/normal","text":"Shrnutí"},{"type":"text/normal","text":"Tento výpis metod klasiﬁkace není vyčerpÆvajícím výčtem, nýbr” jednodu- chým přehledem. Zmíněna nebyla ani kategorie metod, kterØ nevy”adují ozna- čenØ vzory, ale provÆdějí učení za chodu pozorovÆním objekt•."},{"type":"text/large","text":"2.4 SledovÆní objekt•"},{"type":"text/normal","text":"Po nalezení a klasiﬁkaci objektu, nÆsleduje čÆst sledovÆní. Hlavní motivací pro sledovÆní objekt• v sekvenci snímk•, je zachycení jejich pohybu v rÆmci sledo- vanØ scØny. Tato informace m•”e pro některØ aplikace počítačovØho vidění být značně u”itečnÆ, například kv•li kontrole, zda se sledovaný objekt neodchýlil od předem deﬁnovanØ trasy."},{"type":"text/normal","text":"Při sledovÆní objektu je po”adovaným cílem, v ka”dØm snímku video sek- vence, nalØzt novou polohu objektu. Pro nalezení novØ polohy se dají vyu”it například techniky, kdy objekt sledujeme vyu”itím algoritm• speciÆlně ur- čenØ pro sledovÆní, kterØ budou zmíněny ní”e, nebo postup, kdy se detekují a klasiﬁkují objekty v ka”dØm snímku zvlÆ†· a jen jsou vzÆjemně porovnÆ- vÆny s nalezenými objekty ze snímku předchozího. Oba tyto postupy mají svØ pro a proti. Například pokud bude k dispozici kvalitní model pozadí, detekce objekt• popředí je jednoduchÆ a relativně nenÆročnÆ operace. Ale pokud ob- jekt splyne s pozadím, například díky dlouhØ nehybnosti, objekt se „ztratí“. Kombinace obou postup• by mohla přinØst dobrØ výsledky."},{"type":"text/normal","text":"Tato sekce bude zaměřenÆ na popis algoritm• pro sledovÆní. ZÆkladem pro tyto operace, je potřeba vyu”ít na reprezentaci objektu vhodnou formu, kterÆ se m•”e li†i pro ka”dý případ a postup sledovÆní. Kdy” je potřeba sle- dovat jeden malý objekt, postačí na jeho reprezentaci jen jediný bod, proto”e jiný objekt nem•”e ani se sledovaným přijít do styku. Proto je u vybírÆní tØ sprÆvnØ metody potřeba brÆt ohled i na podmínky, za kterých se bude ob- jekty sledovat. Například pokud je jedinou součÆstí scØny sledovaný objekt a pozadí je statickØ, nebo se pozadí mění v pr•běhu času a mohou nastat ko-"},{"type":"text/normal","text":"ObrÆzek 2.11: Rozdělení sledovacích metod. Převzato z publikace [23]."},{"type":"text/normal","text":"lize mezi sledovanými objekty, kterØ nesmějí nijak naru†it sprÆvnost sledovÆní. V†echny po”adavky je potřeba předem znÆt, aby byla vybrÆna ta nejvhodněj†í a nejrobustněj†í metoda pro danØ podmínky. Na diagramu 2.4 jsou znÆzorněny metody sledovÆní a jejich zařazení."},{"type":"text/plus","text":"2.4.1 Optický tok"},{"type":"text/normal","text":"Optický tok je obecně vnímÆní vizuÆlního pohybu objekt• v•či pozorovateli. V reÆlnØm prostředí tedy optický tok pozorovatelØ určují z pozorovÆní okolního světa, jako je určení směru pohybu jedoucího auta nebo „pohyb“ statických objekt•, kdy” se pohybuje pozorovatel. V počítačovØm vidění je optický tok metoda pro určení pohybu bodu"},{"type":"text/small","text":"2"},{"type":"text/normal","text":"oproti předchozím snímk•m. Optický tok se dÆ vyu”ívat takØ pro zji†tění vzdÆlenosti objekt• a to na zÆkladě informace o rychlosti pozorovatele a vek- toru pohybu bod•, proto”e objekty blí”e pozorovateli budou mít vět†í pohyb ne” vzdÆleněj†í objekty. Proto se metoda optickØho toku takØ vyu”ívÆ v robo- tice na řízení a automatickØmu vyhýbÆní překÆ”ek. Optický tok staví na předpokladu, ”e pokud se intenzita hodnoty pixelu v aktuÆlním snímku změnila oproti předchozímu, znamenÆ to pohyb. Pokud by se ale optický tok vypočítÆval pouze na œrovni pixel•, mohl by mít velice †patnØ výsledky na sprÆvnØ určení směru pohybu. Proto se bere v potaz i okolí pixelu. Dal†ím předpokladem je fakt, ”e okolí pixelu mÆ stÆle stejnou intenzitu a jas barvy, i kdy” se poloha m•”e změnit. Navíc sousední body jsou vět†inou součÆstí stejnØ plochy a proto mohou mít takØ stejný směr a rychlost pohybu. Pokud bude scØna obsahovat objekt, například kouli, kterÆ mÆ jednolitou barvu a bude se pohybovat kolem svØ osy, metoda optickØho toku tento pohyb"},{"type":"text/small","text":"2"},{"type":"text/small","text":"feature je v tomto případě bod a jeho okolí"},{"type":"text/normal","text":"nezachytí. Objekt se sice pohybuje, ale ”Ædný z bod• snímku nemění svoji intenzitu a ani jas, a proto se zdÆ být objekt stÆle statický. Kdybychom ale začali pohybovat zdrojem světla, vyvolalo by to změny jasu jednotlivých bod• a tím pÆdem i pohyb."},{"type":"text/normal","text":"Existují dvě kategorie optickØho toku, kterØ se nazývají řídký a hustý op- tický tok. Na obrazech 2.4.3 a 2.4.3 jsou obě znÆzorněny."},{"type":"text/normal","text":"Hustý optický tok"},{"type":"text/normal","text":"Do tØto kategorie patří například metody [24, 25]. Slovo hustý zde odrÆ”í skutečnost, ”e je optický tok počítÆn pro v†echny body snímku. Někdy je takØ označovÆna slovem globÆlní."},{"type":"text/normal","text":"Tento přístup umo”‹uje zji†tění pohybu v†ech čÆstí scØny a díky tomu do- stat kompletní přehled o dění na pozorovanØ scØně. To se vyu”ívÆ například v navigačních systØmech nebo robotice. GraﬁckØ znÆzornění m•”e být barev- nou mapou, kde se jednotlivØ vektory pohybu obarví podle velikosti nebo směru."},{"type":"text/normal","text":"Řídký optický tok"},{"type":"text/normal","text":"Na rozdíl od předchozího kategorie, se zde pracuje jen s určitou mno”inou bod•, kterØ se metodou optickØho toku sledují. Nejroz†ířeněj†í je metoda [26]."},{"type":"text/normal","text":"Nejprve je potřeba získat mno”inu bod•, kterÆ bude vhodnÆ pro sledovÆní. Na to se vyu”ívají feature detektory popsanØ dříve. Body jsou na aktuÆlním snímku hledÆny v okolí p•vodní polohy a to maximÆlně v určitØm rozsahu. Proto se m•”e stÆt, ”e díky vysokØ rychlosti objektu, mohou být některØ body při sledovÆní ztraceny, nebo naopak u některých nesprÆvně určena novÆ po- loha."},{"type":"text/normal","text":"Optický tok a sledovÆní objekt•"},{"type":"text/normal","text":"Pro sledovÆní objekt• pomocí optickØho toku, je potřeba si nejenom uchovÆ- vat danou mno”inu bod•, podle kterých je objekt sledovÆn, ale takØ informaci o struktuře objektu, jako obrys nebo ohraničující obdØlník. Proto”e samo- statnØ body nemají dostatek informací, o sledovanØm objektu, na to, aby se mohl vypočítat nový obrys objektu."},{"type":"text/plus","text":"2.4.2 Kalman ﬁltr"},{"type":"text/normal","text":"JednÆ se o pravděpodobnostní metodu, zalo”enou na měření informací z dří- věj†ích pozorovÆní a výstupem je předpoklÆdanÆ novÆ poloha sledovanØho ob- jektu. Proto”e kalman ﬁltr je zalo”en na měření více proměnných a bere v po- taz i †um naměřených dat, je více přesný v predikcích ne” algoritmy, kterØ by stavěly jen na jednØ z těchto proměnných. Takto vytvÆří model pohybu objektu pro maximÆlní přesnost predikce novØ polohy."},{"type":"text/normal","text":"X = K ∗ Z + (1 − K ) ∗ X + ω (2.6)"},{"type":"text/small","text":"t t  t t   t t  t t    t−1 t t  t t   t t  t t    t−1  t t  t t   t t  t t    t−1 t t  t t   t t  t t    t−1   t−1"},{"type":"text/normal","text":"Rovnice 2.6 obecně popisuje jak Kalman ﬁltr provÆdí predikci aktuÆlní po-"},{"type":"text/small","text":"3"},{"type":"text/normal","text":"lohy X . K je míra učení , Z je odhadnutÆ poloha a X označuje předchozí"},{"type":"text/small","text":"t t  t t   t t  t t    t−1 t t  t t   t t  t t    t−1  t t  t t   t t  t t    t−1 t t  t t   t t  t t    t−1   t−1"},{"type":"text/normal","text":"polohu. Výhodou Kalman ﬁltru je pou”ívÆní †umu ω při predikci. PředpoklÆdÆ se ”e †um mÆ Gaussovu distribuci, i kdy” v reÆlnØm prostředí to nemusí být v”dy přesný odhad. Postup kalman ﬁltru se sklÆdÆ ze dvou krok•:"},{"type":"text/normal","text":"1. Predikce – ﬁltr na zÆkladě vytvořenØho modelu odhadne novou polohu objektu."},{"type":"text/normal","text":"2. Korekce – přesnÆ naměřenÆ hodnota polohy je ﬁltru předÆna, aby mohl v dal†ím kroku zlep†it svoji predikci."},{"type":"text/normal","text":"Kalman ﬁltr je, podle p•vodní deﬁnice, vhodný hlavně pro sledovÆní ob- jekt• s lineÆrním pohybem, vět†ina sledovaných objekt• mÆ ale nelineÆrní po- hyb a proto byly vyvinuty modiﬁkace roz†iřující klasický Kalman ﬁltr o pod- poru predikce nelineÆrních pohyb•."},{"type":"text/plus","text":"2.4.3 Mean-shift a Cam-shift"},{"type":"text/normal","text":"Při sledovÆní objekt• pomocí mean-shift algoritmu, je daný objekt reprezen- tovaný histogramem v barevnØm spektru. JednÆ se o iterační metodu, kterÆ hledÆ objekt v novØm snímku dokud nenajde oblast její” histogram mÆ nejlep†í shodu s histogramem reprezentující objekt, nebo do zadanØ mo”nØ odchylky. Díky tØto reprezentaci a mo”nØ odchylce při hledÆní, se tato metoda hodí pro sledovÆní objekt•, její” tvar se m•”e měnit. Cam-shift, na rozdíl od mean-shift, periodicky upravuje histogram repre- zentující objekt a rozlo”ení features. To umo”‹uje dynamicky upravovat veli- kost sledovanØho objektu."},{"type":"text/normal","text":"Předchozí tři kapitoly jsou popsÆny velice dobře ve člÆnku [23], který obsahuje přehled a popis metod jak detekce, tak i sledovÆní objekt•."},{"type":"text/small","text":"3"},{"type":"text/small","text":"Kalman ﬁltr je rekurzivní metoda a vyu”ívÆ vÆ”ený pr•měr pro hodnoty"},{"type":"text/normal","text":"ObrÆzek 2.12: UkÆzka zobrazení hustØho optickØho toku. Zdroj [27]."},{"type":"text/normal","text":"ObrÆzek 2.13: SledovÆní bod• pomocí optickØho toku. Zdroj [27]."},{"type":"text/large","text":"Kapitola"},{"type":"text/small","text":"3"}]},{"name":"Analýza a nÆvrh","content":[{"type":"text/normal","text":"V tØto kapitole budou představeny ji” existující systØmy a aplikace. PotØ bude představeno zvolenØ implementační prostředí systØmu, který je výstupem tØto prÆce."},{"type":"text/large","text":"3.1 PublikovanØ techniky"},{"type":"text/plus","text":"Histogram orientovaných gradient• (HOG)"},{"type":"text/normal","text":"HOG je technika popisu objektu pomocí histogram•, kterØ jsou vyu”ívÆny jako features. HOG se pou”ívÆ pro detekci a klasiﬁkaci naučených objekt• a v dne†ní době je to jeden z nejpou”ívaněj†ích algoritm• při detekci lidí."},{"type":"text/normal","text":"Detektor vyu”ívÆ HOG pro reprezentaci objektu jeho celkovou podobu, ni- koli jen mno”inu features, u kterých by si dÆle potřeboval uchovÆvat informace o jejich zvÆjemnØm vztahu."},{"type":"text/normal","text":"Vyu”ití HOG, pro œčely detekce lidí, bylo prvně publikovÆno Dalalem a Triggsem [28]. Ve svØ verzi pou”ívají tedy HOG na popis objektu a pomocí tØto reprezentace naučí SVM klasiﬁkÆtor rozpoznÆvat osoby, viz obraz 3.1."},{"type":"text/normal","text":"Objekt, který je potřeba detekovat, je rozdělen na men†í, překrývající se bloky, a pro ka”dý tento blok je vypočítÆn histogram orientace. Spojením v†ech blok• se vytvoří model objektu. V†echny vstupní vzory, na kterých se SVM klasiﬁkÆtor učí, musí mít stejnØ rozměry. V [28] pou”ívají vzory člověka s rozměry 64×128. Pro zaji†tění sprÆvnØho fungovÆní je potřeba, aby hledaný objekt, ve vstupních datech, měl stejnØ, nebo vět†í rozměry, ne” na kterých byl detektor naučený."},{"type":"text/normal","text":"HledÆní člověka ve vstupním obrazu se provÆdí pomocí klouzavØho okØnka. Je tedy prohledÆvÆn postupně celý obraz na přítomnost objektu a oblasti, kterØ mají dostatečnou shodu s vytvořeným modelem jsou označeny jako člověk."},{"type":"text/normal","text":"ObrÆzek 3.1: Vizualizace HOG deskriptoru. Zdroj [29]."},{"type":"text/normal","text":"SledovÆní pomocí HOG deskriptor•"},{"type":"text/normal","text":"Proto”e HOG je jen určitÆ forma reprezentace oblasti, nemusí se pou”ívat jen při detekci objekt•. Například v [30] je popsÆna metoda jak pomocí HOG deskriptor• sledovat objekty, navíc je tato metoda odolnÆ i na překrytí ob- jekt•. Autor nejprve pro ka”dý sledovaný objekt nalezne význačnØ body FAST detektorem [7] a potØ pro ka”dý vypočítal HOG deskriptor, jejich” pomocí je objekt sledovÆn."},{"type":"text/plus","text":"Dal†í metody"},{"type":"text/normal","text":"DÆle budou lehce představeny dal†í existující projekty."},{"type":"text/normal","text":"Multi-Target Tracking in Real-Time Surveillance Video[31] Tato metoda a implementace jsou zajímavØ předev†ím výkonem. Umo”- ‹uje toti” detekci a sledovÆní osob v reÆlnØm čase na videu ve vysokØm rozli†ení. Pro detekci byl autory pou”it HOG deskriptor a pro sledovÆní metoda KLT [9]. Takových výsledk• autoři dosÆhli díky optimalizovanØ, více vlÆknovØ implementaci."},{"type":"text/normal","text":"Tracking-Learning-Detection [32] V tØto prÆci autor vyvinul metodu pro dlouhodobØ sledovÆní objektu. Objekt je reprezentovÆn plochou, přesněji ohraničujícím obdØlníkem, ve kterØ se nachÆzí. Při sledovÆní objektu si tento algoritmus zÆrove‹ vy- tvÆří i model objektu. Díky tomu se m•”e detekce postupem času i zlep- †ovat."},{"type":"text/normal","text":"Continuous Energy Minimization for Multi-Target Tracking [33] V tØto publikaci se autor zabývÆ sledovÆním objekt• pomocí hledÆní optimÆlní trajektorie objekt•."},{"type":"text/normal","text":"click2stream [34] Click2stream je komerční aplikace, kterÆ nabízí klient•m zpracovÆní vi- dea z IP kamer. Tento portÆl poskytuje slu”by jako teplotní mapy po- hybu a počítÆní pohybujících se objekt•."},{"type":"text/normal","text":"Google Tango [35] Tento projekt je zde zařazen hlavně díky svØ jedinečnosti. Zatím se jednÆ o prototyp telefonu, který by měl být schopný „vnímat“ okolí a pohyb stejným zp•sobem jako lidØ. Telefon obsahuje spoustu senzor• snímají- cích pohyb zařízení a pomocí toho m•”e vytvÆřet například 3D model okolního. Mo”nosti vyu”ití takovØho zařízení jsou obrovskØ, například usnadnit pohyb a navigaci zrakově handicapovaných lidem."},{"type":"text/large","text":"3.2 Implementační prostředí"},{"type":"text/normal","text":"Navrhovaný systØm bude implementovÆn vyu”itím těchto prostředk•:"},{"type":"text/plus","text":"3.2.1 OpenCV"},{"type":"text/normal","text":"Tato knihovna obsahuje implementace algoritm• počítačovØho vidění a stro- jovØho učení. Cílem vývoje knihovny OpenCV je poskytnout ucelený nÆstroj pro zpracovÆní obrazu a tím zjednodu†it vývoj nových projekt•. OpenCV se dÆ pova”ovat za takový standard v počítačovØm vidění a knihovna je hodně roz†ířenÆ i mezi společnostmi jako Google a Microsoft [36]. Knihovna OpenCV je uvolněna ve formě otevřených zdrojových kódu, proto ji m•”e kdokoli upra- vovat nebo přidÆvat novØ algoritmy."},{"type":"text/normal","text":"Knihovna OpenCV byla vybrÆna hlavně pro svou kvalitu implementace algoritm• a roz†ířenosti. Navíc přímo podporuje vývoj aplikací v programova- cím jazyce Python 3.2.2. Při implementaci byla pou”ita verze OpenCV 2.4.8."},{"type":"text/normal","text":"Mo”nØ alternativy"},{"type":"text/normal","text":"OpenCV obsahuje pravděpodobně největ†í kolekci optimalizovaných algoritm• pro potřeby počítačovØho vidění, ale existují i jinØ mo”nØ alternativy. Sim- pleCV [37] není alternativa v œplnØm slova smyslu, proto”e v sobě zahrnuje OpenCV i dal†í knihovny, ale zjednodu†uje a sjednocuje jejich rozhraní."},{"type":"text/normal","text":"Mo”nou alternativou je si pou”ívanØ algoritmy implementovat a nepou”ívat hotovØ knihovny. TakovØ ře†ení je nejlep†í hlavně případě, kdy je překÆ”kou rozhraní algoritm•, kterØ nedisponují potřebnými funkcemi."},{"type":"text/plus","text":"3.2.2 Python"},{"type":"text/normal","text":"Python je interpretovaný objektový programovací jazyk [38]. Zdrojový kód je nejprve přelo”en interpretem do spustitelnØ podoby a potØ spu†těn. Proto pokud je dostupný tento interpret na nějakØ platformě, například Windows nebo Linux, je takØ kód v Pythnu spustitelný na tØto platformě a není potřeba nijak zasahovat do samotnØ struktury zdrojovØho kódu programu. Díky tomu je Python jednodu†e přenositelný. Jeho vývoj je takØ ve formě otevřených zdrojových kód•. Přenositelnost, jednoduchost a efektivita vývoje byly hlavními faktory při rozhodnutí vybrat Python na implementaci systØmu. OpenCV ve verzi 2.4.8 podporuje pouze Python verze 2.x a proto pro implementaci byl pou”it Python verze 2.7.6 místo nejnověj†í verze 3.4."},{"type":"text/normal","text":"Mo”nØ alternativy"},{"type":"text/normal","text":"Vybrat sprÆvný programovací jazyk pro implementaci nemusí být zcela jedno- duchÆ zÆle”itost. Proto”e stejnÆ œloha implementovanÆ v jednom programo- vacím jazyce m•”e bě”et rychleji ne” v jinØm. Python je interpretovaný jazyk, který se překlÆdÆ do spustitelnØ podoby a” při spu†tění programu. To m•”e hrÆt roli při výkonnosti. Na rozdíl od toho jsou programovací jazyky C a C++ předkompilovÆny a výsledkem tØto operace je binÆrní spustitelný soubor. Ve srovnÆní s Pythonem dosahuje C++ v rychlosti kódu v”dy lep†ích výsledk• [39, 40]. Proto vyu”ití jazyka C nebo C++ je dobrou volbou, hlavně pro systØmy kde je d•le”itÆ výslednÆ rychlost."},{"type":"text/large","text":"3.3 NavrhovanØ ře†ení"},{"type":"text/normal","text":"Pro realizaci navrhovanØho systØmu byly vybrÆny tyto algoritmy:"},{"type":"text/normal","text":"Metoda odčítÆní pozadí pro segmentaci objekt• popředí od pozadí,"},{"type":"text/normal","text":"Optický tok pro sledovÆní objekt• a"},{"type":"text/normal","text":"HOG a SVM pro klasiﬁkaci pohybujících se objekt•."},{"type":"text/normal","text":"Pro segmenatci pohybujících objekt• od pozadí se dÆ vyu”it i optický tok, přesněji hustý optický tok 2.4.1, ale v porovnÆní s odčítÆním pozadí, je více nÆchylný na změny osvětlení a †um scØny. NěkterØ tyto nedostatky mohou být odstraněny pou”itím dal†ích metod jako hranový detektor, který je odolný na změny osvětlení [41]."},{"type":"text/large","text":"Kapitola"},{"type":"text/small","text":"4"}]},{"name":"Realizace","content":[{"type":"text/normal","text":"V tØto kapitole bude popsÆna implementace a pou”itØ funkce knihovny OpenCV. VýslednÆ implementace mÆ tuto souborovou strukturu:"},{"type":"text/normal","text":"main.py – JednÆ se o hlavní soubor pomocí kterØho se celÆ aplikace spou†tí. Nastavují se zde potřebnØ počÆteční proměnnØ."},{"type":"text/normal","text":"moan_common.py – Jsou zde nadeﬁnovÆny pomocnØ proměnnØ, funkce a třídy, kterØ se vyu”ívají v ostatních čÆstech kódu."},{"type":"text/normal","text":"moan_tracker.py – Třída implementující sledovÆní objekt•."},{"type":"text/normal","text":"moan_detector.py – Obsahuje algoritmus pro detekci a klasiﬁkaci objekt•."},{"type":"text/normal","text":"moan_heatmap – Obsahuje třídu, kterÆ se starÆ o uklÆdÆní a vykreslovÆní teplotní mapy."},{"type":"text/large","text":"4.1 Detekce a klasiﬁkace objekt•"},{"type":"text/normal","text":"Pro nalezení objekt• byla pou”ita dříve popsanÆ metoda odčítÆní pozadí. OpenCV nabízí přes rozhraní cv2.BackgroundSubtractorMOG(). JednÆ se o třídu kompletně implementující potřebnØ algoritmy a je zalo”ena na postupu popsanØm v [18]. Je tedy vyu”ito více Gaussovských křivek pro reprezentaci mo”ných hodnot pixelu. KonkrØtně byly pou”ity tři a oproti pou”ití pěti se pr•měrnÆ doba zpracovÆní jednoho snímku sní”ila přibli”ně 1.3×."},{"type":"text/normal","text":"Proto”e vstupní data ani model pozadí nejsou v”dy dokonalØ, je nejprve potřeba ze vstupních snímk• odstranit †um, pro jeho odstranění se pou”ívÆ metoda cv2.GaussianBlur(), který vstupní snímek rozostří. OpenCV nabízí mnoho metod na rozostření obrazu, ale †um z reÆlnØho prostředí mÆ podobnou distribuci jako Gaussova. Dal†ího sní”ení doby zpracovÆní jednoho snímku se docílilo zmen†ením rozměr• vstupního obrazu a to zase přibli”ně 1.3×."},{"type":"text/normal","text":"ObrÆzek 4.1: ChybnÆ klasiﬁkace objekt• m•”e být i kdy” jsou plně viditelnØ. ÚdajnØ postavy jsou ohraničeny."},{"type":"text/normal","text":"V ka”dØm iteraci systØmu je načten jeden snímek, z videa nebo přímo z webkamery, odečteno pozadí, prahovÆn a výstupem je binÆrní obraz s vy- značenými oblastmi pohybu. Tento obraz je dÆle zpracovÆn pomocí funkce cv2.findContours(), který vrací seznam v†ech nalezených objekt• ve formě obrysu. ZnÆzorněno na obrazech B. Klasiﬁkace objekt• pomocí HOG deskriptoru cv2.HOGDescriptor(), který v OpenCV nabízí ji” naučený klasiﬁkÆtor na rozpoznÆvÆní osob. Tento klasiﬁ- kÆtor je ale naučený na vzorech o rozměrech 64 × 128 a proto v†echny oblasti musejí být nejprve pře†kÆlovÆny, aby osoba v oblasti měla minimÆlně tyto rozměry. Tento krok si ale vy”aduje předem znÆmý rozměr osob, kterØ se ve vstupních datech nachÆzejí. I přes dobrou kalibraci rozměr•, nedosahuje kla- siﬁkace dobrých výsledk• a m•”e se stÆt, ”e jen jeden objekt z celØho videa bude klasiﬁkovÆn. Navíc je klasiﬁkace velice časově nÆročnÆ, a její nÆročnost se zvy†uje s počtem nalezených objekt• v aktuÆlním snímk•. Příklady †patnØ klasiﬁkace na obrazu 4.1 a v příloze B."},{"type":"text/large","text":"4.2 SledovÆní objekt•"},{"type":"text/normal","text":"SledovÆní objekt• bylo prvně zamý†leno provÆdět tak, ”e by pro ka”dý sledo- vaný objekt byly nalezeny klíčovØ body, tedy features, a ty pomocí optickØho toku sledovat. Navíc OpenCV disponuje hotovým ře†ením, jak features de- tektoru (například cv2.ORB, cv2.FAST, cv2.SURF), tak i k hledÆní optickØho toku bod• na nÆsledující snímek cv2.calcOpticalFlowPyrLK(). Optický tok pro mno”inu bod• funguje spolehlivě, je ale potřeba pomocí dal†ích heuristik odstra‹ovat „zbloudilØ“ body. Proto byly odstraněny v”dy body, kterØ měli vět†í vzdÆlenost od svØho předka ne” hodnota mediÆnu v†ech vzdÆleností."},{"type":"text/normal","text":"ObrÆzek 4.2: Úspě†nØ sledovÆní objektu."},{"type":"text/normal","text":"Po nalezení bod• na novØm snímku, se vypočítala mo”nÆ oblast, kde by se objekt mohl nachÆzet, a pro zpřesnění polohy byl pou”it CAM-shift cv2.CamShift(). Pro CAM-shift je ale potřeba předzpracovat prohledÆvanou oblast, co” takØ zpomalovalo běh programu."},{"type":"text/normal","text":"Výsledkem byl velice †patný koncept sledovÆní. Proto byla implemento- vÆn jednoduchý algoritmus, který sleduje objekty jen na zÆkladě jejich polohy. V ka”dØm novØm snímku jsou nalezeny objekty popředí, kterØ jsou porovnÆ- vÆny s objekty nalezenými na předchozím snímku, na zÆkladě jejich střed•, jak znÆzor‹uje algoritmus 4.1."},{"type":"text/normal","text":"4.1 SledovÆní objekt• na zÆkladě polohy"},{"type":"text/normal","text":"1. Nalezni objekty na snímku t a vlo” do mno”iny Q ."},{"type":"text/small","text":"t"},{"type":"text/normal","text":"2. Nalezni středy objekt• Q ."},{"type":"text/small","text":"t"},{"type":"text/normal","text":"3. Ka”dý objekt ze mno”iny Q , jeho” střed se nalØzÆ v nějakØm objektu"},{"type":"text/small","text":"t−1"},{"type":"text/normal","text":"z Q , je stejný objekt."},{"type":"text/small","text":"t"},{"type":"text/normal","text":"4. Pro v†echny objekty z Q , kterØ nebyly takto nalezeny, najdi nejbli”-"},{"type":"text/small","text":"t−1"},{"type":"text/normal","text":"†ího souseda z Q , a ty jsou stejný objekt."},{"type":"text/small","text":"t"},{"type":"text/normal","text":"Výhodou tohoto přístupu je nízkÆ nÆročnost na výkon. Dokonce sledovÆní objektu není nijak †patnØ a algoritmus dokÆ”e sledovat objekt po celou dobu jeho pohybu. ProblØm nastÆvÆ u čÆstečnØho a plnØho překrytí jinými objekty. Proto”e u objekt• není sledovÆn ”Ædný jiný feature ne” poloha, není po oddě- lení mo”nØ rozeznat který objekt je který. Pro potřeby tvorby teplotních map je ale tento postup dostačující. Příklad sledovÆní pomocí polohy je znÆzorněn na obrazu 4.2 a B je ukÆzka kolize dvou objekt•."},{"type":"text/large","text":"4.3 Teplotní mapa"},{"type":"text/normal","text":"Teplotní mapa je implementovÆna jako dvourozměrnØ pole, kdy se pozice od- povídající poloze objektu inkrementuje. Inkrementace se provÆdí bu⁄ o kon- stantu, nebo o hodnotu o kterou se objekt posunul z přede†lØho snímku. Takto uchovanÆ informace se musí obarvit podle barevnØho schØma. Na to je vyu”itÆ funkce z OpenCV cv2.applyColorMap() a barevnØ schØma COLORMAP_JET. Oba zp•soby vykreslovÆní jsou znÆzorněny na obrazech B. ProblØm m•”e nastat u dlouhých videozÆznam•, nebo· datový typ prvk• pole je 32bitový ﬂoat a m•”e dojít k jeho přetečení."},{"type":"text/large","text":"4.4 Zhodnocení a testovÆní bakalÆřskØ prÆce"},{"type":"text/normal","text":"Po”adavky na realizaci byly odli†nØ od výslednØ implementace systØmu. Bylo po”adovÆno aby systØm uměl rozeznat osoby od ostatních objekt•, ale kv•li nedokonalØmu sledovÆní bylo od tohoto cíle upu†těno. Výsledkem praktickØ"},{"type":"text/small","text":"4"},{"type":"text/normal","text":"čÆsti je spí†e takový proof-of-concept systØm, který představuje některØ tech- niky počítačovØho vidění. ProblØm u sledovÆní optickým tokem, jeho” vyře†ením by se mohla zlep†it jeho œspě†nost, je výpočet aktuÆlní polohy objektu, kterÆ zÆvisí hlavně na sledovaných bodech. Zlep†ení výsledk• klasiﬁkace by se mohlo docílit naučením vlastního kla- siﬁkÆtoru na vzorech, kterØ odpovídají objekt•m na konkrØtních vstupních datech. Ale to by znamenalo zlep†ení jen pro tyto konkrØtní data, nikoli v obec- nØm měřítku. TestovÆní systØmu bylo provÆděno na videozÆznamech nalezených u jiných projekt• na počítačovØ vidění. Na strÆnkÆch [42] je k dispozici velkÆ kolekce zdroj•."},{"type":"text/plus","text":"4.4.1 Dal†í vývoj"},{"type":"text/normal","text":"Pro dal†í rozvoj systØmu by bylo potřeba vyladit existující implementaci a to zejmØna sledovÆní objekt•. Dal†í mo”ností m•”e být parametrizovat některØ operace, aby mohl být systØm lØpe nastaven na konkrØtní vstupní data. Proto”e s mnoha věcmi se při nÆvrhu systØmu nepočítalo, obsahuje kód spoustu duplicitních čÆstí, proto by před dal†ím vývojem bylo potřeba takØ přepracovat projekt, aby struktura více odpovídala aktuÆlnímu konceptu. Je takØ potřeba vyře†it uklÆdÆní teplotních map, aby výsledek mohl být tvořen pro zÆznamy dlouhØ i několik dní. Mo”ným ře†ením by mohla být nor- malizace dat, ale je potřeba dbÆt na validitu ulo”ených dat."},{"type":"text/small","text":"4"},{"type":"text/small","text":"Představení konceptu a existence ře†ení"}]},{"name":"ZÆvěr","content":[{"type":"text/normal","text":"Cílem tØto prÆce bylo navrhnout a implementovat systØm pro analýzu pohybu videa a vhodnou formou reprezentovat naměřenØ œdaje. Nejprve byla vypraco- vÆna re†er†e existujících postup• a mo”ných ře†ení na zÆkladě publikovaných člÆnk•, podle kterých byl navrhnut ideÆlní stav systØm. NÆsledně se provÆděli experimenty s navrhovanými algoritmy a jejich zhodnocení. Bohu”el nebylo mo”nØ v†echny plně demonstrovat. Nakonec se nepodařilo implementovat systØm pokrývající v plnØm rozsahu zadanØ po”adavky. Byly ale alespo‹ poskytnuty informace o technikÆch počí- tačovØho vidění a přehled existujících postup• v tØto oblasti. Pro výraznØ zlep†ení by bylo potřeba navrhnout jinØ postupy ne” zvo- lenØ při implementaci. PočítačovØ vidění je nÆročný obor, a proto navrhnutí systØmu s vysokou œspě†ností, je nezbytenØ se plně seznÆmit s danou proble- matikou."}]},{"name":"Literatura","content":[{"type":"text/normal","text":"[1] Discover Real Immersive Interactive Computing | Kinect for Windows. DostupnØ z: http://www.microsoft.com/en-us/kinectforwindows/"},{"type":"text/normal","text":"[2] Griswold, A.: How Retailers Track Shoppers In Heat Maps - Business In- sider. DostupnØ z: http://www.businessinsider.com/how-retailers- track-shoppers-in-heat-maps-2014-1"},{"type":"text/normal","text":"[3] Hama-Girl: Mew. DostupnØ z: http://hama-girl.deviantart.com/art/ Mew-308535128"},{"type":"text/normal","text":"[4] Canny, J.: A Computational Approach to Edge Detection. Pattern Analy- sis and Machine Intelligence, IEEE Transactions on, ročník PAMI-8, č. 6, nov 1986: s. 679–698, ISSN 0162-8828, doi:10.1109/tpami.1986.4767851. DostupnØ z: http://dx.doi.org/10.1109/tpami.1986.4767851"},{"type":"text/normal","text":"[5] Sobel, I.; Feldman, G.: A 3x3 Isotropic Gradient Operator for Image Processing, 1968, never published but presented at a talk at the Stanford Artiﬁcial Project."},{"type":"text/normal","text":"[6] Kass, M.; Witkin, A.; Terzopoulos, D.: Snakes: Active contour models. IN- TERNATIONAL JOURNAL OF COMPUTER VISION, ročník 1, č. 4, 1988: s. 321–331."},{"type":"text/normal","text":"[7] Rosten, E.; Drummond, T.: Machine Learning for High-speed Corner Detection. In Proceedings of the 9th European Conference on Computer Vision - Volume Part I, ECCV’06, Berlin, Heidelberg: Springer-Verlag, 2006, ISBN 3-540-33832-2, 978-3-540-33832-1, s. 430–443, doi:10.1007/ 11744023_34. DostupnØ z: http://dx.doi.org/10.1007/11744023_34"},{"type":"text/normal","text":"[8] Rublee, E.; Rabaud, V.; Konolige, K.; aj.: ORB: An eﬃcient alternative to SIFT or SURF. In Computer Vision (ICCV), 2011 IEEE International Conference on, Nov 2011, ISSN 1550-5499, s. 2564–2571, doi:10.1109/ ICCV.2011.6126544."},{"type":"text/normal","text":"[9] Shi, J.; Tomasi, C.: Good features to track. In Computer Vision and Pattern Recognition, 1994. Proceedings CVPR ’94., 1994 IEEE Compu- ter Society Conference on, Jun 1994, ISSN 1063-6919, s. 593–600, doi: 10.1109/CVPR.1994.323794."},{"type":"text/normal","text":"[10] Kdejsme.cz | Četnost příjmení nebo jmØna v ČeskØ republice. DostupnØ z: http://www.kdejsme.cz/prijmeni/DvořÆk/hustota/"},{"type":"text/normal","text":"[11] Disney wikia: Olaf. DostupnØ z: http://disney.wikia.com/wiki/File: Olaf_transparent.png"},{"type":"text/normal","text":"[12] A Threshold Selection Method from Gray-Level Histograms. Systems, Man and Cybernetics, IEEE Transactions on, ročník 9, č. 1, Jan 1979: s. 62–66, ISSN 0018-9472, doi:10.1109/TSMC.1979.4310076."},{"type":"text/normal","text":"[13] MacQueen, J.: Some methods for classiﬁcation and analysis of multi- variate observations. In Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Statistics, Berke- ley, Calif.: University of California Press, 1967, s. 281–297. DostupnØ z: http://projecteuclid.org/euclid.bsmsp/1200512992"},{"type":"text/normal","text":"[14] Davies, E.: Computer and Machine Vision: Theory, Algorithms, Practi- calities. Academic Press, Elsevier, 2012, ISBN 9780123869081. DostupnØ z: http://books.google.cz/books?id=AhVjXf2yKtkC"},{"type":"text/normal","text":"[15] OpenCV dev team: How to Use Background Subtraction Methods - OpenCV 3.0.0-dev documentation. DostupnØ z: http://docs.opencv.org/trunk/doc/tutorials/video/ background_subtraction/background_subtraction.html"},{"type":"text/normal","text":"[16] Wren, C.; Azarbayejani, A.; Darrell, T.; aj.: Pﬁnder: real-time tracking of the human body. Pattern Analysis and Machine Intelligence, IEEE Transactions on, ročník 19, č. 7, Jul 1997: s. 780–785, ISSN 0162-8828, doi:10.1109/34.598236."},{"type":"text/normal","text":"[17] Stauﬀer, C.; Grimson, W. E. L.: Adaptive background mixture models for real-time tracking. In Computer Vision and Pattern Recognition, 1999. IEEE Computer Society Conference on., ročník 2, 1999, ISSN 1063-6919, s. –252 Vol. 2, doi:10.1109/CVPR.1999.784637."},{"type":"text/normal","text":"[18] Kaewtrakulpong, P.; Bowden, R.: An improved adaptive background mix- ture model for real-time tracking with shadow detection. In Proceedings of 2nd European Workshop on Advanced Video Based Surveillance Systems, ročník 5308, 2001."},{"type":"text/normal","text":"[19] Achkar, F.: Hysteresis-based selective Gaussian-Mixture model for real- time background update and object detection, 2006. DostupnØ z: http: //spectrum.library.concordia.ca/9285/"},{"type":"text/normal","text":"[20] Bouwmans, T.; El Baf, F.; Vachon, B.: Background Modeling using Mix- ture of Gaussians for Foreground Detection - A Survey. Recent Patents on Computer Science, ročník 1, č. 3, Nov 2008: s. 219–237. DostupnØ z: http://hal.archives-ouvertes.fr/hal-00338206/en/"},{"type":"text/normal","text":"[21] Toyama, K.; Krumm, J.; Brumitt, B.; aj.: Wallﬂower: principles and practice of background maintenance. In Computer Vision, 1999. The Pro- ceedings of the Seventh IEEE International Conference on, ročník 1, 1999, s. 255–261 vol.1, doi:10.1109/ICCV.1999.791228."},{"type":"text/normal","text":"[22] Belongie, S.; Malik, J.; Puzicha, J.: Shape matching and object recogni- tion using shape contexts. Pattern Analysis and Machine Intelligence, IEEE Transactions on, ročník 24, č. 4, Apr 2002: s. 509–522, ISSN 0162- 8828, doi:10.1109/34.993558."},{"type":"text/normal","text":"[23] Yilmaz, A.; Javed, O.; Shah, M.: Object Tracking: A Survey. ACM Comput. Surv., ročník 38, č. 4, Dec 2006, ISSN 0360-0300, doi: 10.1145/1177352.1177355. DostupnØ z: http://doi.acm.org/10.1145/ 1177352.1177355"},{"type":"text/normal","text":"[24] Horn, B. K. P.; Schunck, B. G.: Determining Optical Flow. ARTIFICAL INTELLIGENCE, ročník 17, 1981: s. 185–203."},{"type":"text/normal","text":"[25] Farnebäck, G.: Two-frame Motion Estimation Based on Polynomial Expansion. In Proceedings of the 13th Scandinavian Conference on Image Analysis, SCIA’03, Berlin, Heidelberg: Springer-Verlag, 2003, ISBN 3-540-40601-8, s. 363–370. DostupnØ z: http://dl.acm.org/ citation.cfm?id=1763974.1764031"},{"type":"text/normal","text":"[26] Lucas, B. D.; Kanade, T.: An Iterative Image Registration Technique with an Application to Stereo Vision. In Proceedings of the 7th International Joint Conference on Artiﬁcial Intelligence - Volume 2, IJCAI’81, San Francisco, CA, USA: Morgan Kaufmann Publishers Inc., 1981, s. 674–679. DostupnØ z: http://dl.acm.org/citation.cfm?id=1623264.1623280"},{"type":"text/normal","text":"[27] Optical Flow – OpenCV-Python Tutorials 1 documentation. Do- stupnØ z: opencv-python-tutroals.readthedocs.org/en/latest/ py_tutorials/py_video/py_lucas_kanade/py_lucas_kanade.html"},{"type":"text/normal","text":"[28] Dalal, N.; Triggs, B.: Histograms of oriented gradients for human de- tection. In Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on, ročník 1, June 2005, ISSN 1063- 6919, s. 886–893 vol. 1, doi:10.1109/CVPR.2005.177."},{"type":"text/normal","text":"[29] Object detection. DostupnØ z: http://www.cs.cornell.edu/courses/ CS4670/2012fa/projects/p5/index.html"},{"type":"text/normal","text":"[30] Garate, C.; Bilinski, P.; Bremond, F.: Crowd Event Recognition using HOG Tracker. In Twelfth IEEE International Workshop on Perfor- mance Evaluation of Tracking and Surveillance (PETS-Winter), Snow- bird, UT, United States: IEEE, Prosinec 2009, s. 1–6, doi:10.1109/PETS- WINTER.2009.5399727. DostupnØ z: http://hal.inria.fr/inria- 00515197"},{"type":"text/normal","text":"[31] Benfold, B.; Reid, I.: Stable Multi-Target Tracking in Real-Time Surve- illance Video. In CVPR, June 2011, s. 3457–3464."},{"type":"text/normal","text":"[32] Kalal, Z.; Mikolajczyk, K.; Matas, J.: Tracking-Learning-Detection. IEEE Trans. Pattern Anal. Mach. Intell., ročník 34, č. 7, jul 2012: s. 1409– 1422, ISSN 0162-8828, doi:10.1109/TPAMI.2011.239. DostupnØ z: http: //dx.doi.org/10.1109/TPAMI.2011.239"},{"type":"text/normal","text":"[33] Milan, A.; Roth, S.; Schindler, K.: Continuous Energy Minimization for Multitarget Tracking. IEEE TPAMI, ročník 36, č. 1, 2014: s. 58–72, ISSN 0162-8828, doi:10.1109/TPAMI.2013.103."},{"type":"text/normal","text":"[34] Click2Stream | If cameras are eyes. We give them brains. DostupnØ z: http://www.click2stream.com"},{"type":"text/normal","text":"[35] ATAP Project Tango – Google. DostupnØ z: https://www.google.com/ atap/projecttango/"},{"type":"text/normal","text":"[36] OpenCV. DostupnØ z: http://opencv.org/"},{"type":"text/normal","text":"[37] SimpleCV. DostupnØ z: http://www.simplecv.org/"},{"type":"text/normal","text":"[38] Python Software Foundation: Welcome to Python.org. DostupnØ z: www.python.org"},{"type":"text/normal","text":"[39] onlyjob: Perl, Python, Ruby, PHP, C, C++, Lua, tcl, javascript and Java benchmark/comparison. DostupnØ z: http://onlyjob.blogspot.cz/ 2011/03/perl5-python-ruby-php-c-c-lua-tcl.html"},{"type":"text/normal","text":"[40] mandelbrot benchmark | Computer Language Benchmarks Game. DostupnØ z: http://benchmarksgame.alioth.debian.org/u32/ performance.php?test=mandelbrot&sort=fullcpu"},{"type":"text/normal","text":"[41] SuganyaDevi, K.; Malmurugan, N.; Sivakumar, R.: EFFICIENT FORE- GROUND EXTRACTION BASED ON OPTICAL FLOW AND SMED FOR ROAD TRAFFIC ANALYSIS. In International Journal of Cyber- Security and Digital Forensics (IJCSDF), Nov 2012, s. 177–182."},{"type":"text/normal","text":"[42] CV Datasets on the web. DostupnØ z: http://www.cvpapers.com/ datasets.html"},{"type":"text/large","text":"Příloha"},{"type":"text/small","text":"A"}]},{"name":"Seznam pou”itých zkratek","content":[{"type":"text/normal","text":"2D Dvojrozměrný prostor"},{"type":"text/normal","text":"3D Trojrozměrný prostor"},{"type":"text/normal","text":"RGB Red-Green-Blue (ČervenÆ-ZelenÆ-ModrÆ). VýslednÆ barva je slo”ena z intenzit těchto tří barev."},{"type":"text/normal","text":"fps Frames per second"},{"type":"text/normal","text":"ms Milisekunda. 1 sekunda = 1000 milisekund"},{"type":"text/large","text":"Příloha"},{"type":"text/small","text":"B"}]},{"name":"Snímky z aplikace","content":[{"type":"text/normal","text":"ObrÆzek B.1: Jedna postava na levØm obrazu nebyla detekovÆna, ale na pravØm ji” ano."},{"type":"text/normal","text":"ObrÆzek B.2: První obraz je teplotní mapa podle pohybu objektu a druhý přičítÆním konstanty."},{"type":"text/normal","text":"ObrÆzek B.3: Po kolizi dvou objekt• algoritmus nesprÆvně přiřadí p•vodní ID."},{"type":"text/normal","text":"ObrÆzek B.4: vstupní obraz, popředí scØny, nalezenØ obrysy"},{"type":"text/large","text":"Příloha"},{"type":"text/small","text":"C"}]},{"name":"U”ivatelskÆ příručka","content":[{"type":"text/normal","text":"Seznam parametr•:"},{"type":"text/normal","text":"−v | −−verbose – Pokud je tento parametr pou”it, zobrazí se doba za jakou je zpracovÆn jeden snímek a aktuÆlní fps."},{"type":"text/normal","text":"−h | −−help – Zobrazí nÆpověd•."},{"type":"text/normal","text":"−s | −−source – Slou”í pro zadÆní vstupního videozÆznamu."},{"type":"text/normal","text":"−t | −−type – Typ tvorby teplotní mapy. Dvě mo”nØ hodnoty 0 a 1."},{"type":"text/normal","text":"−e | −−experimental – Zapne experimentÆlní funkce klasiﬁkace a sledovÆní objekt• pomocí optickØho toku."},{"type":"text/normal","text":"−o | −−output – Soubor do kterØho se mÆ ulo”it výslednÆ teplotní mapa."},{"type":"text/normal","text":"−−width – Šířka vstupního videa. Slou”í pro kalibraci při pou”ití kamery."},{"type":"text/normal","text":"−−height – Vý†ka vstupního videa. Slou”í pro kalibraci při pou”ití kamery."},{"type":"text/large","text":"Příloha"},{"type":"text/small","text":"D"}]},{"name":"Obsah přilo”enØho CD","content":[{"type":"text/normal","text":"readme.txt...................................stručný popis obsahu CD samples.......................................testovací videozÆznamy src impl...................................zdrojovØ kódy implementace main.py moan_common.py moan_detector.py moan_heatmap.py moan_tracker.py"},{"type":"text/small","text":"A"},{"type":"text/normal","text":"thesis......................zdrojovÆ forma prÆce ve formÆtu LT X E images BP_Cvacho_Ondrej_2014.tex csn690.bst cvut-logo-bw.pdf FITthesis.cls mybibliographyfile.bib text.......................................................text prÆce BP_Cvacho_Ondrej_2014.pdf............text prÆce ve formÆtu PDF"}]}],"background_color":"inherit","font_color":"inherit","paper_name":"Analýza pohybu pro staticky umístěnou kameru","author":"Ondřej Cvacho"}
